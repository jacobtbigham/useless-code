{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unnecessarily Loose Reverse Syllabic Word Pairs\n",
    "Depending on the company, here's a fun party game: find words from whom the interchange of first and last syllables generates a new word. For example, reversing the first and last syllables of *treaty* gives you *tea tree*. At first, you can likely think of a few fun ones, but it quickly becomes difficult to venture beyond two-syllable words and compound nouns. Python to the rescue! I've processed the 134,000-word Carnegie Mellon phonetic dictionary for any words whose beginning and end can be swapped to create a new word. In this set, there are 473 such words (0.35%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and prepping the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_f = pd.read_csv(\"phonetic_dict.txt\", sep=\"  \", header=None, engine = \"python\")\n",
    "data_f.columns = [\"word\", \"pronunciation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pronunciation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>AABERG</td>\n",
       "      <td>AA1 B ER0 G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>AACHEN</td>\n",
       "      <td>AA1 K AH0 N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>AACHENER</td>\n",
       "      <td>AA1 K AH0 N ER0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>AAH</td>\n",
       "      <td>AA1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>AAKER</td>\n",
       "      <td>AA1 K ER0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>AALIYAH</td>\n",
       "      <td>AA2 L IY1 AA2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>AALSETH</td>\n",
       "      <td>AA1 L S EH0 TH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>AAMODT</td>\n",
       "      <td>AA1 M AH0 T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>AANCOR</td>\n",
       "      <td>AA1 N K AO2 R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>AARDEMA</td>\n",
       "      <td>AA0 R D EH1 M AH0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word      pronunciation\n",
       "0    AABERG        AA1 B ER0 G\n",
       "1    AACHEN        AA1 K AH0 N\n",
       "2  AACHENER    AA1 K AH0 N ER0\n",
       "3       AAH                AA1\n",
       "4     AAKER          AA1 K ER0\n",
       "5   AALIYAH      AA2 L IY1 AA2\n",
       "6   AALSETH     AA1 L S EH0 TH\n",
       "7    AAMODT        AA1 M AH0 T\n",
       "8    AANCOR      AA1 N K AO2 R\n",
       "9   AARDEMA  AA0 R D EH1 M AH0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_f.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need to translocate the last syllable of each word to find matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pronunciation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>AABERG</td>\n",
       "      <td>B ER0 G AA1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>AACHEN</td>\n",
       "      <td>K AH0 N AA1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>AACHENER</td>\n",
       "      <td>N ER0 AA1 K AH0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>AAH</td>\n",
       "      <td>AA1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>AAKER</td>\n",
       "      <td>K ER0 AA1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>AALIYAH</td>\n",
       "      <td>AA2 AA2 L IY1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>AALSETH</td>\n",
       "      <td>S EH0 TH AA1 L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>AAMODT</td>\n",
       "      <td>M AH0 T AA1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>AANCOR</td>\n",
       "      <td>K AO2 R AA1 N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>AARDEMA</td>\n",
       "      <td>M AH0 AA0 R D EH1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word      pronunciation\n",
       "0    AABERG        B ER0 G AA1\n",
       "1    AACHEN        K AH0 N AA1\n",
       "2  AACHENER    N ER0 AA1 K AH0\n",
       "3       AAH                AA1\n",
       "4     AAKER          K ER0 AA1\n",
       "5   AALIYAH      AA2 AA2 L IY1\n",
       "6   AALSETH     S EH0 TH AA1 L\n",
       "7    AAMODT        M AH0 T AA1\n",
       "8    AANCOR      K AO2 R AA1 N\n",
       "9   AARDEMA  M AH0 AA0 R D EH1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def last_syllable_to_front(word):\n",
    "    \"\"\"Moves last consonant-vowel cluster from list of phonemes to the front of the list\n",
    "    \"\"\"\n",
    "    first_vowel_cluster = True\n",
    "    last_index = len(word) - 1\n",
    "    \n",
    "    while last_index > 0:\n",
    "        consonant = word[last_index].isalpha()\n",
    "        if consonant:\n",
    "            if not first_vowel_cluster: #only allow one consonant phoneme before final vowel cluster\n",
    "                break\n",
    "            else:\n",
    "                while consonant and last_index > 0:\n",
    "                    last_index -= 1\n",
    "                    consonant = word[last_index].isalpha()\n",
    "        else: #vowel\n",
    "            if first_vowel_cluster:\n",
    "                last_index -= 1\n",
    "                first_vowel_cluster = False\n",
    "            else:\n",
    "                last_index += 1\n",
    "                break\n",
    "        \n",
    "    x = word[last_index:]\n",
    "    x.extend(word[:last_index])\n",
    "    return \" \".join(x)\n",
    "    \n",
    "data_b = data_f.copy()\n",
    "data_b.pronunciation = data_b.pronunciation.str.split().apply(last_syllable_to_front)\n",
    "data_b.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the matches\n",
    "Now we have two dataframes, `data_f` with normal syllabic order, and `data_b` with the last syllable moved to the front. Now, let's see which syllable orderings are in both dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pronunciation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>AAH</td>\n",
       "      <td>AA1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>AARGH</td>\n",
       "      <td>AA1 R G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>AASE</td>\n",
       "      <td>AA1 S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>AB</td>\n",
       "      <td>AE1 B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>ABBS</td>\n",
       "      <td>AE1 B Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134242</td>\n",
       "      <td>ZURN</td>\n",
       "      <td>Z ER1 N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134244</td>\n",
       "      <td>ZURVE</td>\n",
       "      <td>Z ER1 V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134268</td>\n",
       "      <td>ZYCH</td>\n",
       "      <td>Z AY1 CH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134278</td>\n",
       "      <td>ZYSK</td>\n",
       "      <td>Z IH1 S K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134279</td>\n",
       "      <td>ZYSK(1)</td>\n",
       "      <td>Z AY1 S K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12717 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           word pronunciation\n",
       "3           AAH           AA1\n",
       "12        AARGH       AA1 R G\n",
       "22         AASE         AA1 S\n",
       "24           AB         AE1 B\n",
       "90         ABBS       AE1 B Z\n",
       "...         ...           ...\n",
       "134242     ZURN       Z ER1 N\n",
       "134244    ZURVE       Z ER1 V\n",
       "134268     ZYCH      Z AY1 CH\n",
       "134278     ZYSK     Z IH1 S K\n",
       "134279  ZYSK(1)     Z AY1 S K\n",
       "\n",
       "[12717 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_both = data_f.pronunciation.isin(data_b.pronunciation)\n",
    "both = data_f[in_both]\n",
    "both"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because many of the words in the set are only one syllable, of course they appear in both dataframes!\n",
    "\n",
    "Let's screen for only those that have more than one syllable by reusing the last_syllable_to_front code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_b</th>\n",
       "      <th>pronunciation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>412</td>\n",
       "      <td>ABT(1)</td>\n",
       "      <td>EY1 B IY1 T IY1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>447</td>\n",
       "      <td>AC</td>\n",
       "      <td>EY1 S IY1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>686</td>\n",
       "      <td>ACHEE</td>\n",
       "      <td>AH0 CH IY1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1037</td>\n",
       "      <td>ADEE</td>\n",
       "      <td>AH0 D IY1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1055</td>\n",
       "      <td>ADELPHI</td>\n",
       "      <td>AH0 D EH1 L F IY0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130098</td>\n",
       "      <td>WHEDON</td>\n",
       "      <td>W EH1 D AH0 N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130155</td>\n",
       "      <td>WHELAN</td>\n",
       "      <td>W EH1 L AH0 N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>131745</td>\n",
       "      <td>WIZEN</td>\n",
       "      <td>W AY1 Z AH0 N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>133753</td>\n",
       "      <td>ZELMA</td>\n",
       "      <td>Z EH1 L M AH0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134090</td>\n",
       "      <td>ZOLA</td>\n",
       "      <td>Z OW1 L AH0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         word_b      pronunciation\n",
       "412      ABT(1)    EY1 B IY1 T IY1\n",
       "447          AC          EY1 S IY1\n",
       "686       ACHEE         AH0 CH IY1\n",
       "1037       ADEE          AH0 D IY1\n",
       "1055    ADELPHI  AH0 D EH1 L F IY0\n",
       "...         ...                ...\n",
       "130098   WHEDON      W EH1 D AH0 N\n",
       "130155   WHELAN      W EH1 L AH0 N\n",
       "131745    WIZEN      W AY1 Z AH0 N\n",
       "133753    ZELMA      Z EH1 L M AH0\n",
       "134090     ZOLA        Z OW1 L AH0\n",
       "\n",
       "[506 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def more_than_one_syllable(word):\n",
    "    \"\"\"Returns whether (T/F) the input word (list of phonemes) is more than one syllable\n",
    "    \"\"\"\n",
    "    first_vowel_cluster = True\n",
    "    last_index = len(word) - 1\n",
    "    \n",
    "    while last_index > 0:\n",
    "        consonant = word[last_index].isalpha()\n",
    "        if consonant:\n",
    "            if not first_vowel_cluster: #only allow one consonant phoneme before final vowel cluster\n",
    "                break\n",
    "            else:\n",
    "                while consonant and last_index > 0:\n",
    "                    last_index -= 1\n",
    "                    consonant = word[last_index].isalpha()\n",
    "        else: #vowel\n",
    "            if first_vowel_cluster:\n",
    "                last_index -= 1\n",
    "                first_vowel_cluster = False\n",
    "            else:\n",
    "                last_index += 1\n",
    "                break\n",
    "        \n",
    "    x = word[last_index:]\n",
    "    x.extend(word[:last_index])\n",
    "    return word != x #if the modified version is the same as the original, then it's only one syllable\n",
    "\n",
    "both_filtered = both[both.pronunciation.str.split().apply(more_than_one_syllable)]\n",
    "both_filtered.columns = [\"word_b\", \"pronunciation\"]\n",
    "both_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's find the corresponding pairs, remove duplicates (since we should expect some pairs to appear twice), and sort by word length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_b</th>\n",
       "      <th>pronunciation</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ABT(1)</td>\n",
       "      <td>EY1 B IY1 T IY1</td>\n",
       "      <td>BTA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>AC</td>\n",
       "      <td>EY1 S IY1</td>\n",
       "      <td>CA(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ACHEE</td>\n",
       "      <td>AH0 CH IY1</td>\n",
       "      <td>CHIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ADEE</td>\n",
       "      <td>AH0 D IY1</td>\n",
       "      <td>DHIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ADEE</td>\n",
       "      <td>AH0 D IY1</td>\n",
       "      <td>DIA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_b    pronunciation   word\n",
       "0  ABT(1)  EY1 B IY1 T IY1    BTA\n",
       "1      AC        EY1 S IY1  CA(1)\n",
       "2   ACHEE       AH0 CH IY1   CHIA\n",
       "3    ADEE        AH0 D IY1   DHIA\n",
       "4    ADEE        AH0 D IY1    DIA"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs = both_filtered.merge(data_b, on=\"pronunciation\", how=\"left\")\n",
    "pairs.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BORNSTEIN, STEINBORN',\n",
       " 'CLAREMONT, MONTCLAIR',\n",
       " 'CLERMONT, MONTCLAIR',\n",
       " 'TOUCHTON, UNTOUCHED',\n",
       " 'BEHOLDER, HOLDERBY',\n",
       " 'LIQUIDE, WAIDELICH',\n",
       " 'FORESTRY, REFOREST',\n",
       " 'BERNAY, NEIGHBOUR',\n",
       " 'BOUNDARY, REBOUND',\n",
       " 'BURCHAM, SCHAMBER',\n",
       " \"CHIEFFO, O'KEEFFE\",\n",
       " 'COSTLOW, LOW-COST',\n",
       " 'FAREWELL, WELFARE',\n",
       " 'LIQUIDE, WEIDLICH',\n",
       " 'ELLEMANN, MANELLA',\n",
       " \"MONROE'S, ROSEMAN\",\n",
       " 'EVERMORE, MOREVER',\n",
       " 'PERREAULT, ROEPER',\n",
       " 'ANDRIES, REASONED',\n",
       " 'REQUEST, WESTRICH',\n",
       " 'REQUEST, WESTRICK',\n",
       " 'ADDRESSED, RESTED',\n",
       " 'ADELPHI, DELPHIA',\n",
       " 'BARABAR, BARBERA',\n",
       " 'BERNAY, NEIGHBOR',\n",
       " 'BONDAR, DARBONNE',\n",
       " 'CELLPRO, PROCELL',\n",
       " \"CHIEFFO, O'KEEFE\",\n",
       " 'CHIEFFO, OKEEFFE',\n",
       " 'ALLCORN, CORNALL',\n",
       " 'DHAHARAN, RHONDA',\n",
       " 'ALLPHIN, FINNELL',\n",
       " 'JERMAINE, MANGER',\n",
       " 'KEMPTON, UNKEMPT',\n",
       " 'LHEUREUX, OEHLER',\n",
       " 'EHRLICH, LIQUEUR',\n",
       " 'MELANIE, NIEMELA',\n",
       " 'ALLNUTT, NUTTALL',\n",
       " 'PERREAULT, ROPER',\n",
       " 'ALDRIC, RECALLED',\n",
       " 'OTTOSEN, SAINATO',\n",
       " 'ASTAIRE, TERRACE',\n",
       " 'BOUSKA, CABOOSE',\n",
       " 'BOWDEN, UNBOWED',\n",
       " 'AMBURN, BURNHAM',\n",
       " 'CHIEFFO, OKEEFE',\n",
       " 'COMMISH, MYSZKA',\n",
       " 'CONCISE, SYSCON',\n",
       " 'CONCUR, KIRCHEN',\n",
       " 'CONNOTE, OETKEN',\n",
       " 'CORDELL, DELCOR',\n",
       " 'ALLCORN, CORNEL',\n",
       " 'ADDAIR, DARRAGH',\n",
       " 'DARRELLE, ELDER',\n",
       " 'DEROUEN, WENDER',\n",
       " 'DHAHARAN, RANDA',\n",
       " 'DHAHARAN, RONDA',\n",
       " 'DHAHRAN, RHONDA',\n",
       " 'DUSSEAULT, SODA',\n",
       " 'FURLAUD, LOAFER',\n",
       " 'GERMAIN, MANGER',\n",
       " 'GERMANE, MANGER',\n",
       " 'LHEUREUX, OHLER',\n",
       " 'ERLICH, LIQUEUR',\n",
       " 'ERLICK, LIQUEUR',\n",
       " 'ELAMIN, MINELLA',\n",
       " 'ELMORE, MORRELL',\n",
       " 'MELANY, NIEMELA',\n",
       " 'ALLNUTT, NUTTAL',\n",
       " 'ALLNUTT, NUTTLE',\n",
       " 'ALPERN, PERNELL',\n",
       " 'ALPERN, PURNELL',\n",
       " 'ENTRIES, RESENT',\n",
       " \"ENROLL, ROLLIN'\",\n",
       " 'OTTOSON, SONATA',\n",
       " 'UNVEIL, VEILLON',\n",
       " 'IRVETTE, VETERE',\n",
       " 'IRVETTE, VETTER',\n",
       " 'AERIAL, ALARIE',\n",
       " 'ABOARD, BOARDA',\n",
       " 'BODEN, UNBOWED',\n",
       " 'BORDEAU, DOBER',\n",
       " 'ABBOUD, BUDDHA',\n",
       " 'AMBURN, BURNAM',\n",
       " 'BURRELL, ELBER',\n",
       " 'BUTTREY, REBUT',\n",
       " 'CAPELLE, PELKA',\n",
       " 'CAUDELL, DELCO',\n",
       " 'CHALOUX, LUCIA',\n",
       " 'ALCOCK, COCKLE',\n",
       " 'COMEAUX, MOCHA',\n",
       " 'ALCON, CONNELL',\n",
       " 'ALCON, CONNOLE',\n",
       " 'CORKEN, UNCORK',\n",
       " 'CURRAGH, OCCUR',\n",
       " 'DANELLE, ELDEN',\n",
       " 'DANELLE, NELDA',\n",
       " 'ADAIR, DARRAGH',\n",
       " 'DELMA, MADELLE',\n",
       " 'DEVELLE, VELDA',\n",
       " 'DHAHRAN, RANDA',\n",
       " 'DHAHRAN, RONDA',\n",
       " 'DOANNA, NADEAU',\n",
       " 'DOCKEN, UNDOCK',\n",
       " 'DOKKEN, UNDOCK',\n",
       " 'DONNELL, ELDON',\n",
       " 'DUSSAULT, SODA',\n",
       " 'ELMER, MIRELLE',\n",
       " 'COLIER, ERCOLE',\n",
       " 'COLYER, ERCOLE',\n",
       " 'AFFAIR, FARRAH',\n",
       " 'FARREN, UNFAIR',\n",
       " 'FARRON, UNFAIR',\n",
       " 'FERMIN, INFIRM',\n",
       " 'FERRAN, UNFAIR',\n",
       " 'FERREN, UNFAIR',\n",
       " 'FERRON, UNFAIR',\n",
       " 'FIRMIN, INFIRM',\n",
       " 'FOLDEN, UNFOLD',\n",
       " 'FURLAN, UNFURL',\n",
       " 'ELGIN, GINNELL',\n",
       " 'HARSHA, SHAHAR',\n",
       " 'JUSTEN, UNJUST',\n",
       " 'JUSTIN, UNJUST',\n",
       " 'ALCOCK, KOCHEL',\n",
       " 'LAREAU, OEHLER',\n",
       " 'LEIKEN, UNLIKE',\n",
       " 'LESSEN, UNLESS',\n",
       " 'LESSON, UNLESS',\n",
       " 'ALLAYED, LEYDA',\n",
       " 'LHEUREUX, OLER',\n",
       " 'LICHEN, UNLIKE',\n",
       " 'LOCKEN, UNLOCK',\n",
       " 'LOKKEN, UNLOCK',\n",
       " 'LOWDEN, UNLOAD',\n",
       " 'GROMA, MACGRAW',\n",
       " 'MAIDEN, UNMADE',\n",
       " 'MAYDEN, UNMADE',\n",
       " 'MONROE, ROHMAN',\n",
       " 'MONROE, ROMANN',\n",
       " 'MOZELLE, ZELMA',\n",
       " 'ANNETTE, NETTA',\n",
       " 'NOVA, VIENNEAU',\n",
       " 'ALPIN, PINNELL',\n",
       " 'REDDEN, UNREAD',\n",
       " 'RESTON, UNREST',\n",
       " 'RINGEN, UNRING',\n",
       " 'ENROLL, ROLLIN',\n",
       " 'SEATON, UNSEAT',\n",
       " 'SEDDON, UNSAID',\n",
       " 'SEETON, UNSEAT',\n",
       " 'EXCEL, SELLECK',\n",
       " 'SELLEN, UNSELL',\n",
       " 'EXCEL, SELLICK',\n",
       " 'SELLON, UNSELL',\n",
       " 'EXCEPT, SEPTIC',\n",
       " 'SOLDAN, UNSOLD',\n",
       " 'ATTESTS, TESSA',\n",
       " \"O'TOOLE, TULLO\",\n",
       " 'TURNIP, UPTURN',\n",
       " 'HOLIAN, UNHOLY',\n",
       " 'HOLIEN, UNHOLY',\n",
       " 'OVAL, VEILLEUX',\n",
       " 'ALVITE, VITALE',\n",
       " 'ANWELL, WEHLAN',\n",
       " 'UNWELL, WEHLAN',\n",
       " 'ANWELL, WELLEN',\n",
       " 'UNWELL, WELLEN',\n",
       " 'ANWELL, WHELAN',\n",
       " 'UNWELL, WHELAN',\n",
       " 'ALARIE, ARIEL',\n",
       " 'ALLAIS, LAYAH',\n",
       " 'ALROY, ROYALL',\n",
       " 'ANSWER, SARAN',\n",
       " \"AREA'S, AZERI\",\n",
       " \"BARRO, O'BARR\",\n",
       " 'BAUCUM, CUMBO',\n",
       " 'ABELE, BELLAH',\n",
       " 'BERNAY, NABER',\n",
       " 'ABBETT, BETTA',\n",
       " 'BONNEAU, OBON',\n",
       " 'ABOARD, BORDA',\n",
       " 'ABOOD, BUDDHA',\n",
       " \"BURGO, O'BERG\",\n",
       " 'BUTTRY, REBUT',\n",
       " \"C'MON, MANCHA\",\n",
       " 'CARESS, ESKER',\n",
       " 'COMEAU, MOCHA',\n",
       " 'COMEAUX, MOCA',\n",
       " 'COMEAUX, MOKA',\n",
       " 'ACCORD, CORDA',\n",
       " 'CORELL, ELCOR',\n",
       " 'DANELL, ELDEN',\n",
       " 'DANELL, NELDA',\n",
       " 'ADELLE, DELLA',\n",
       " 'DELLA, UDELLE',\n",
       " 'DUMAIS, MAIDA',\n",
       " 'DUMAIS, MAYDA',\n",
       " 'DUPER, PERDUE',\n",
       " 'DUPER, PURDUE',\n",
       " 'DUSSEAU, SODA',\n",
       " 'DYSAN, SUNDAI',\n",
       " 'DYSON, SUNDAI',\n",
       " 'EAGAR, GUERRY',\n",
       " 'EAGER, GUERRY',\n",
       " 'AFFAIR, FARAH',\n",
       " 'FARON, UNFAIR',\n",
       " 'FATAH, OFFUTT',\n",
       " 'AFFAIR, FERRA',\n",
       " 'AFFIRM, FIRMA',\n",
       " 'FITTON, UNFIT',\n",
       " 'GALORE, ORGEL',\n",
       " 'AGAIN, GUENNA',\n",
       " \"HERRO, O'HAIR\",\n",
       " \"HERRO, O'HARE\",\n",
       " 'ADJUST, JUSTA',\n",
       " 'EICHEN, KANAI',\n",
       " 'ACHENE, KEENA',\n",
       " 'ACCORD, KORDA',\n",
       " 'LAREAU, OHLER',\n",
       " 'LAROUX, UHLER',\n",
       " 'LAROUX, UHLIR',\n",
       " 'LEMIEUX, MULA',\n",
       " 'LENORE, ORLAN',\n",
       " 'LEROUX, UHLER',\n",
       " 'LEROUX, UHLIR',\n",
       " 'LIENAU, NOLLA',\n",
       " 'LIKEN, UNLIKE',\n",
       " 'ASLIN, LINNAS',\n",
       " 'LODEN, UNLOAD',\n",
       " 'LYCAN, UNLIKE',\n",
       " 'LYKIN, UNLIKE',\n",
       " 'MADAN, UNMADE',\n",
       " 'MADEN, UNMADE',\n",
       " 'EMAIL, MAILEY',\n",
       " 'MERCI, SIEMER',\n",
       " 'MONROE, ROMAN',\n",
       " 'MOREAU, OHMER',\n",
       " 'MORTIE, TIMOR',\n",
       " 'MUNRO, ROHMAN',\n",
       " 'MUNRO, ROMANN',\n",
       " 'ANNEAL, NEALA',\n",
       " 'ANETTE, NETTA',\n",
       " 'ANNETT, NETTA',\n",
       " \"DELEO, O'DELI\",\n",
       " 'OTERI, TERRIO',\n",
       " 'PADEN, UNPAID',\n",
       " 'APPALL, PAULA',\n",
       " 'OPAQUE, PAYCO',\n",
       " 'PETRI, REPEAT',\n",
       " 'APPEAL, PIELA',\n",
       " 'PURSUE, SUPER',\n",
       " 'PURVEY, VAPOR',\n",
       " 'ENROLL, ROLIN',\n",
       " 'ANCEL, SELLEN',\n",
       " 'ANSEL, SELLEN',\n",
       " 'ANCEL, SELLON',\n",
       " 'ANSEL, SELLON',\n",
       " 'ASSESS, SESSA',\n",
       " 'SETON, UNSEAT',\n",
       " 'ASSUME, SUMMA',\n",
       " 'ATTEST, TESTA',\n",
       " 'TURVEY, VATER',\n",
       " 'OVAL, VALLEAU',\n",
       " 'AVERSE, VERSA',\n",
       " 'UNWED, WHEDON',\n",
       " 'UNWISE, WIZEN',\n",
       " 'ADER, DORAIS',\n",
       " 'AGER, GERAIS',\n",
       " 'AKALI, CALIA',\n",
       " 'ALLAIS, LEYA',\n",
       " 'ALLAY, LAYAH',\n",
       " 'ALROY, ROYAL',\n",
       " 'AMER, MORAIS',\n",
       " 'ANDER, DURAN',\n",
       " 'ANEW, HUGHEN',\n",
       " 'APPLY, PLAYA',\n",
       " 'AREAS, AZERI',\n",
       " 'BALLOU, LUBA',\n",
       " 'ALBAN, BANAL',\n",
       " \"BARO, O'BARR\",\n",
       " 'BARRO, OBARR',\n",
       " 'BASAM, SAMBA',\n",
       " 'ABAIR, BEARA',\n",
       " 'ABELE, BELLA',\n",
       " 'ABEND, BENDA',\n",
       " 'ABAIR, BERRA',\n",
       " 'BHUTTO, TOBU',\n",
       " 'BISSO, OBESE',\n",
       " 'BODA, DUBEAU',\n",
       " 'BOLA, LABEAU',\n",
       " 'ABOTT, BOTTA',\n",
       " 'BUETOW, TOBU',\n",
       " 'COMEAU, MOCA',\n",
       " 'COMEAU, MOKA',\n",
       " 'COMMA, MCCAA',\n",
       " 'ACORD, CORDA',\n",
       " 'COREL, ELCOR',\n",
       " 'COTTEE, TECO',\n",
       " 'DARGA, GODAR',\n",
       " 'ADELLE, DELA',\n",
       " 'DELA, UDELLE',\n",
       " 'ADELE, DELLA',\n",
       " 'ADELL, DELLA',\n",
       " \"DELO, O'DELL\",\n",
       " 'DEWAN, UNDUE',\n",
       " 'DEWARR, URDU',\n",
       " \"DEYOE, O'DAY\",\n",
       " \"DEYOE, O'DEA\",\n",
       " 'ARDIN, DINAR',\n",
       " 'DONA, NADEAU',\n",
       " 'ADAN, DONAIS',\n",
       " 'ADEN, DONAIS',\n",
       " 'DONAIS, NEDA',\n",
       " 'DOVEY, VAYDA',\n",
       " 'DUMAIS, MEDA',\n",
       " 'DUPIN, PANDA',\n",
       " 'DUTIL, TILDA',\n",
       " 'DUTIL, TILDE',\n",
       " 'EAMER, MARIE',\n",
       " 'EAMER, MOREE',\n",
       " 'EGER, GUERRY',\n",
       " 'ELMER, MOREL',\n",
       " 'FARRA, REFAH',\n",
       " 'AFFAIR, FERA',\n",
       " 'AFFINE, FINA',\n",
       " 'GAREAU, OGRE',\n",
       " 'AHEAD, HEDDA',\n",
       " 'HERRO, OHAIR',\n",
       " 'HERRO, OHARE',\n",
       " 'AHOLD, HOLDA',\n",
       " 'ACORD, KORDA',\n",
       " 'EILAN, LANAI',\n",
       " 'LAREAU, OLER',\n",
       " 'LARUE, UHLER',\n",
       " 'LARUE, UHLIR',\n",
       " 'ALEEN, LEANA',\n",
       " 'ALENE, LEANA',\n",
       " 'ALEEN, LEENA',\n",
       " 'ALENE, LEENA',\n",
       " 'ALEVE, LEIVA',\n",
       " 'ALAIR, LEORA',\n",
       " 'LIENAU, NOLA',\n",
       " \"LIRO, O'LEAR\",\n",
       " 'ALLOT, LOTTA',\n",
       " 'LOZEAU, ZOLA',\n",
       " 'ALLURE, LURA',\n",
       " 'ALLIED, LYDA',\n",
       " 'ALIGN, LYNNA',\n",
       " 'ALINE, LYNNA',\n",
       " 'EMAIL, MALEY',\n",
       " 'AMASS, MASSA',\n",
       " 'EMAIL, MAYLE',\n",
       " 'AMMEEN, MENA',\n",
       " 'AMMEEN, MINA',\n",
       " 'MITRE, REMIT',\n",
       " 'MONZO, OMANS',\n",
       " 'MOREAU, OMER',\n",
       " 'MORTY, TIMOR',\n",
       " 'MUNRO, ROMAN',\n",
       " 'ANNEAL, NILA',\n",
       " 'ANNAUD, NODA',\n",
       " 'DELEO, ODELE',\n",
       " 'OPAQUE, PACO',\n",
       " 'OPAQUE, PECO',\n",
       " 'APIECE, PISA',\n",
       " 'ERASE, RACEY',\n",
       " 'AASEN, SANAA',\n",
       " 'OSTEN, SANAA',\n",
       " 'ASSUME, SUMA',\n",
       " 'ARTIS, TESAR',\n",
       " 'ATTUNE, TUNA',\n",
       " 'EVENT, VENTI',\n",
       " 'ACHEE, CHIA',\n",
       " 'AKEY, CLEAH',\n",
       " 'ALLAY, LEYA',\n",
       " 'ALLEE, LEAH',\n",
       " 'AMER, MORAY',\n",
       " 'ASAY, SIEJA',\n",
       " 'ABACK, BACA',\n",
       " 'BADA, DABAH',\n",
       " 'BARO, OBARR',\n",
       " 'BARRA, OBAR',\n",
       " 'ABBAS, BASA',\n",
       " 'BEEBE, BIBI',\n",
       " 'BEKAA, CABA',\n",
       " 'ABELE, BELA',\n",
       " 'ABAIR, BERA',\n",
       " 'ABATE, BETA',\n",
       " 'ABET, BETTA',\n",
       " 'ABODE, BODA',\n",
       " 'BOLA, LEBOW',\n",
       " 'ABOR, BORAH',\n",
       " 'CAMA, MCCAA',\n",
       " 'DATA, TODAY',\n",
       " 'ADELE, DELA',\n",
       " 'ADELL, DELA',\n",
       " 'ADEL, DELLA',\n",
       " 'DELO, ODELL',\n",
       " 'DEWAN, UNDO',\n",
       " 'DEWAR, URDU',\n",
       " \"DEYO, O'DAY\",\n",
       " \"DEYO, O'DEA\",\n",
       " 'DEYOE, ODAY',\n",
       " 'ADAK, DHAKA',\n",
       " 'ADORE, DORA',\n",
       " 'DOVEY, VEDA',\n",
       " 'DUNNO, NODA',\n",
       " 'DUNNO, ODEN',\n",
       " 'DUNNO, ODIN',\n",
       " 'AFAR, FARRA',\n",
       " \"GOIN', UNGO\",\n",
       " 'KAMA, MCCAA',\n",
       " 'LAFOE, OLAF',\n",
       " 'ALLOT, LATA',\n",
       " 'LAVIE, VILA',\n",
       " 'ALEM, LEMMA',\n",
       " 'ALEM, LEMME',\n",
       " 'ALEEN, LENA',\n",
       " 'ALENE, LENA',\n",
       " 'LENO, OLEAN',\n",
       " 'LEONE, ONLY',\n",
       " 'ELISE, LESA',\n",
       " 'ALEEN, LINA',\n",
       " 'ALENE, LINA',\n",
       " 'LINO, OLEAN',\n",
       " 'LIOU, OOLEY',\n",
       " 'LIRO, OLEAR',\n",
       " 'ELISE, LISA',\n",
       " 'ALONE, LONA',\n",
       " 'ALOT, LOTTA',\n",
       " 'EMAIL, MALY',\n",
       " 'AMMAN, MANA',\n",
       " 'AMAR, MARRA',\n",
       " 'AMEEN, MENA',\n",
       " 'AMEEN, MINA',\n",
       " 'AMIR, MIRRA',\n",
       " 'ERASE, RACY',\n",
       " 'ASSAD, SADA',\n",
       " 'ADEE, DHIA',\n",
       " 'ALLEE, LIA',\n",
       " 'ANEW, EUAN',\n",
       " 'ANEW, EWAN',\n",
       " 'ANEW, EWEN',\n",
       " 'ABAD, BADA',\n",
       " 'BADU, DUBA',\n",
       " 'BARA, OBAR',\n",
       " 'ABOR, BORA',\n",
       " 'ADEL, DELA',\n",
       " 'DEYO, ODAY',\n",
       " 'DUER, URDU',\n",
       " 'AJAR, JARA',\n",
       " 'AKAO, KAWA',\n",
       " 'AKIN, KYNA',\n",
       " 'ALOT, LATA',\n",
       " 'AMAL, MALA',\n",
       " 'MANO, OMAN',\n",
       " 'AMAR, MARA',\n",
       " 'AMIR, MIRA',\n",
       " 'OCON, QANA',\n",
       " 'AWAD, WADA',\n",
       " 'ADEE, DIA',\n",
       " 'KAO, OKAY',\n",
       " 'LEO, OLEA',\n",
       " 'NOAA, UNO',\n",
       " 'NOAH, UNO',\n",
       " 'ABT, BTA',\n",
       " 'AGEE, GA',\n",
       " 'AGO, GOA',\n",
       " 'MPG, PGM',\n",
       " 'NOA, UNO',\n",
       " 'AC, CA',\n",
       " 'BT, TB']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs.word_b = pairs.word_b.str.replace(\"\\(1\\)\", \"\")\n",
    "pairs.word = pairs.word.str.replace(\"\\(1\\)\", \"\")\n",
    "pairs = pairs.drop(columns = \"pronunciation\")\n",
    "pairs = pd.DataFrame(np.sort(pairs.values, axis=1), columns=pairs.columns).drop_duplicates()\n",
    "unique_pairs = sorted(list(pairs.word_b + \", \" + pairs.word), reverse= True, key=len)\n",
    "unique_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 473 word pairs in the set, which is 0.35% the total number of words\n"
     ]
    }
   ],
   "source": [
    "print(\"There are {} word pairs in the set, which is {:.2f}% the total number of words\"\n",
    "      .format(len(unique_pairs), len(unique_pairs)/len(data_f)*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
